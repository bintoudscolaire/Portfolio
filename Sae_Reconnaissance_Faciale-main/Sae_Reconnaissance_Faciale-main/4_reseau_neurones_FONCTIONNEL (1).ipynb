{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Librairies"
      ],
      "metadata": {
        "id": "NdwnkcCD_fzE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TW2CIcON_dkF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from base64 import b64decode\n",
        "from IPython.display import display, Javascript\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from google.colab.output import eval_js"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création du dataset"
      ],
      "metadata": {
        "id": "VhO3z7MQBMjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== #\n",
        "# Variables globales #\n",
        "# ================== #\n",
        "\n",
        "# Création d'un répertoire data\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.mkdir(\"data\")\n",
        "\n",
        "nb_images_collectees = 10 # Nombre d'image qu'on veut collecter pour chacun des admis et des non admis\n",
        "donnees_visage = [] # Liste vide pour enregistrer les visages\n",
        "\n",
        "# =============================== #\n",
        "# Capture des data: nom et images #\n",
        "# =============================== #\n",
        "\n",
        "# Définition de la fonction pour capturer une photo\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    # On exécute le script JavaScript et on réceptionne l'image capturée sous forme de chaîne de données base64\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # on décode la chaîne base64 pour obtenir les données de l'image en binaire\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    # Sauvegarde des données binaires dans un fichier image\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "# on charge le modèl qui permet de détecter les visage\n",
        "cascade_visage = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "nom = input(\"Entrez votre nom: \")  # pour saisir le nom\n",
        "for i in range(nb_images_collectees):\n",
        "    filename = take_photo()  # Capture la photo\n",
        "    image = cv2.imread(filename)\n",
        "    gris = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    coordonnees_visage = cascade_visage.detectMultiScale(gris, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in coordonnees_visage:\n",
        "        visage = image[y:y+h, x:x+w]\n",
        "        visage_redimensionne = cv2.resize(visage, (50, 50))\n",
        "        donnees_visage.append(visage_redimensionne)\n",
        "        break  # on sauvegarde que la 1er photo\n",
        "\n",
        "# on convertit les données des visages en un tableau numpy\n",
        "donnees_visage = np.array(donnees_visage, dtype='float32')\n",
        "donnees_visage /= 255.0 # on normmalise ces données\n",
        "\n",
        "# Enregistrement des données des noms et des visages\n",
        "noms_path = \"data/noms.pkl\"\n",
        "if os.path.exists(noms_path):\n",
        "    with open(noms_path, 'rb') as file:\n",
        "        noms = pickle.load(file)\n",
        "else:\n",
        "    noms = []\n",
        "\n",
        "noms += [nom] * nb_images_collectees\n",
        "with open(noms_path, 'wb') as file:\n",
        "    pickle.dump(noms, file)\n",
        "\n",
        "visages_path = \"data/visages.pkl\"\n",
        "if os.path.exists(visages_path):\n",
        "    with open(visages_path, 'rb') as file:\n",
        "        visages_existants = pickle.load(file)\n",
        "    visages = np.concatenate((visages_existants, donnees_visage), axis=0)\n",
        "else:\n",
        "    visages = donnees_visage\n",
        "\n",
        "with open(visages_path, 'wb') as file:\n",
        "    pickle.dump(visages, file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U6e6Rzg8AVyU",
        "outputId": "2b432959-b6b7-4220-966d-6e891643b900"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrez votre nom: khaoula\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithme"
      ],
      "metadata": {
        "id": "Un4QJYHNBWZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodage des noms en vecteurs binaires\n",
        "encoder = LabelBinarizer()\n",
        "noms_encoded = encoder.fit_transform(noms)\n",
        "\n",
        "# Diviser les visages et les noms en ensemnle d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(donnees_visage, noms_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# on redimensionne les données\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)  # Aplatit l'ensemble d'entraînement\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)  # Aplatir l'ensemble de test"
      ],
      "metadata": {
        "id": "DIGpOofsBHlc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modèle de réseau de neurones dense\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(encoder.classes_), activation='softmax')\n",
        "])\n",
        "# on compile notre modèle\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle avec un nombre d'époques égal à 10\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Enregistrement du modèle et de l'encodeur\n",
        "model.save('modele_reconnaissance_faciale_dense.keras')\n",
        "with open('encodeur_classes.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xeiYCfGBv7b",
        "outputId": "e5890b9d-1d50-4e15-c490-11d899f9ae46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exécution"
      ],
      "metadata": {
        "id": "I2s1iJhJFHjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du modèle et de l'encodeur\n",
        "modele = load_model('modele_reconnaissance_faciale_dense.keras')\n",
        "with open('encodeur_classes.pkl', 'rb') as f:\n",
        "    encoder = pickle.load(f)\n",
        "filename = take_photo()  # Capture une nouvelle image\n",
        "image = cv2.imread(filename)\n",
        "image = cv2.resize(image, (50, 50))  # Redimensionne la photo prise\n",
        "image = image.astype('float32') / 255.0  # Normalisation\n",
        "image = np.expand_dims(image, axis=0)\n",
        "image = image.reshape(-1, 7500)  # Aplatir l'image\n",
        "\n",
        "# Prédiction\n",
        "prediction = modele.predict(image)\n",
        "classe_predite = encoder.classes_[np.argmax(prediction)]\n",
        "\n",
        "print(f\"Classe prédite : {classe_predite}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "c02ZbN_MFH7M",
        "outputId": "10b4ea1b-d58d-4a68-b328-65f2ea89ad79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');  // bouton pour capture d'image\n",
              "        capture.textContent = 'Capture';\n",
              "        div.appendChild(capture);\n",
              "        // permet l'affichage du flux vidéo de notre caméra en temps réel\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        // l'exécution du script s'interromp jusqu'à ce qu'un clic pour la capture soit effectué\n",
              "        await new Promise((resolve) => capture.onclick = resolve);\n",
              "        //  capture de l'image, arrêt de la caméra, mise en format jpeg de l'image\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = video.videoWidth;\n",
              "        canvas.height = video.videoHeight;\n",
              "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "Classe prédite : khaoula\n"
          ]
        }
      ]
    }
  ]
}